{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo methods: random number generation, *but with more flair*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo methods are a family of methods that rely on random number generation (usually with specific constraints, such as being distributed according to a curve) either to find an approximate solution (most famous example: numerical integration and finding $\\pi$'s digits) or for the sake of RNG itself (such as simulation of experiments). The general downside is that it requires a fairly large amount of extractions to increase accuracy when used for problem solving; the silver lining is that the general principle is *extremely* simple.\n",
    "\n",
    "(or is it?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First taste of RNG: uniformly distributed generation\n",
    "\n",
    "Let's declare 2 variables:\n",
    "$$r_0 = 1 \\qquad m = 37$$\n",
    "where $r_i$ is the i-th random value we extracted (with $r_0$ being the \"seed\" value), $m$ is the number we're using to set a maximum value on our randomly generated numbers. Later on we'll see that this value also puts a cap on the \"randomness\".\n",
    "One first formula we can use for *pseudo*random number generation is\n",
    "$$r_i = (n \\cdot r_{i-1})\\mod m$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "and with the values we chose, this table emerges\n",
    "\n",
    "n  r\n",
    "\n",
    "1  1\n",
    "\n",
    "2  5\n",
    "\n",
    "3  25\n",
    "\n",
    "4  14\n",
    "\n",
    "5  33\n",
    "\n",
    "6  17\n",
    "\n",
    "7  11\n",
    "\n",
    "8  18\n",
    "\n",
    "9  16\n",
    "\n",
    "10  6\n",
    "\n",
    "11 30\n",
    "\n",
    "12 2\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(and so on until the 37th entry cause the professor for whatever reason wasn't happy enough with just 10 entries being a lengthy enough example)\n",
    "\n",
    "**This is pseudorandomness**. However unpredictable this sequence of numbers appears to be, this sequence ***will repeat*** (same order or different order?) from the $m+1$-th entry. On top of that, there's no guarantee that the sequence of random numbers is **uniformly distributed**: it means that there's gonna be strong hidden correlations between the extracted values.\n",
    "\n",
    "To improve on the randomness (which still does not obtain *true* randomness, but we'll take it) we may choose to constantly change $n$ and $m$ during the generation. An example of this is the (whatshisname) method, working with 3 seeds: it's slow, however it has an extraordinarily large period (on the order of $10^{12}$). There's better methods for this.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altering the uniform distribution\n",
    "\n",
    "We start by setting\n",
    "\n",
    "$$ \n",
    "0 < r_i < 1 \\\\\n",
    "s_m < s_i < s_M\n",
    "$$\n",
    "\n",
    "where $s$ is a scaling factor to adjust our distribution bounds. This second \"hypothetical\" distribution $s$ has width $\\Delta s$.\n",
    "\n",
    "$$ s_i = r_i\\Delta s  + s_m $$\n",
    "\n",
    "(or we can subtract $s_M$ alternatively)\n",
    "\n",
    "This gives us a number in a distribution that's scaled and moved vertically.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation method, lookup table method and rejection sampling\n",
    "\n",
    "We may constrain randomness well beyond uniform distributions: we can force number extractions that follow a more general distribution. One consequence is that no matter the choice of distribution, the extracted number has *the same chance of being generated, regardless of choice of distribution*. Recalling, somehow, notions of lab1:\n",
    "$$ \\int_{-\\infty}^r P(r) dr = \\int_{-\\infty}^x g(x)dx $$\n",
    "\n",
    "where $P(r)$ is our known distribution so far, which we already constrained so the integral above may be rewritten as \n",
    "\n",
    "$$\n",
    "\\int_{0}^r dr = \\int_{-\\infty}^x g(x)dx \\\\\n",
    "r_i =  \\int_{-\\infty}^{x_i} g(x)dx\n",
    "$$\n",
    "\n",
    "with $g$ being a generic distribution function. This is an *integral equation* (counterpart to a *differential equation*).\n",
    "\n",
    "Let's take an example distribution $P(x)$:\n",
    "\n",
    "$$ P(x)=\n",
    "\\begin{cases}\n",
    "A(1+ax^2) \\quad &-1 <x< 1 \\\\\n",
    "0 \\quad &\\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\\int_{-1}^x A(1+ax^2)dx = A\\int_{-1}^x (1+ax^2)dx = A\\left[x+\\frac{ax^3}{3}\\right]_{-1}^x = r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we're solving this last bit of the equation (omitting the step where I expand the definite integral bluh bluh). This last equation is nonlinear, so we *could* employ one of our known root-finding algorithms (even though at a glance this is a cubic so it's analytically solvable, but this applies in general with more complicated functions), however that comes with the risk of creating correlation (lowering the \"quality\" of randomness).\n",
    "\n",
    "Another path is sampling the obtained function at regular steps, obtaining a sequence of $x_i$ values, and obtaining a random value $r$ through interpolation. This is called the *lookup table method*, sometimes used. However it may be affected by some bias.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a so called rectangular \"envelope\" (IT: inviluppo) around the curve we're using, generating a pair of values $(r_1, r_2)$ that falls within the rectangle, so the coordinates (x1, y1) will be constrained like\n",
    "$$ r_1 \\rightarrow x_1 =  r_1 \\Delta x + x_{min}$$\n",
    "and similarly $r_2 \\rightarrow y_1 =  r_2 \\Delta y + y_{min}$.\n",
    "In both cases, $\\Delta$ represents the width of the considered interval.\n",
    "\n",
    "In our current case\n",
    "\n",
    "$$r_{1} \\cdot 2 + (-1)$$\n",
    "2 being the width of the interval (-1 to 1) and -1 being $x_{min}$.\n",
    "\n",
    "What we're doing is keeping all the random points that fall *below* the curve, discarding those above. Once we obtain the random $x$ and $y$, we check that $y < g(x)$, in which case we can keep the $x$. This is a good method, but extraordinarily wasteful as the obtained $y$ is only being used for the aforementioned inequality check, wasting calculations (this is called *rejection sampling*), which has an efficiency of 50% and lower."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian distributed values\n",
    "\n",
    "Let's say we take a value $r$ in a range going from $0$ to $N$. The average value in this range will of course be $\\mu = N/2$. Generating $r$ so that it belongs to a Gaussian distribution will be given by\n",
    "\n",
    "$$r_g = \\sum^N_{i=1} r_i - \\mu$$\n",
    "\n",
    "with $r_i$ being the usual random values from 0 to 1. The width $\\sigma$ of the curve will be $\\sqrt{N/12}$ (???), so a Gaussian centered in 0 and of width 1, we need to pick $\\mu = 0, \\sigma = 1 \\implies N=12$.\n",
    "\n",
    "This is *spectacularly inefficient* as only one number over the 12 generated values will *actually belong to the distribution*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box-Mueller method\n",
    "Let's take the general Probability Density Function (Gaussian curve) *in one variable*:\n",
    "\n",
    "$$G(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}}$$\n",
    "\n",
    "We can actually create a Gaussian function in 2 variables: recalling again notions from lab1, the probability of obtaining a tuple of multiple values equals the product of the probabilities to obtain each single value\n",
    "\n",
    "$$G(x,y) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}}\\cdot\\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{y^2}{2}} = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2+y^2}{2}}$$\n",
    "\n",
    "and graphically speaking we may examine just a cross section of said surface: this means we're just seeing a circle (with a certain radius $R$) on the cartesian xy plane. Let's swap from cartesian to polar coords. This means we're gonna be checking whether our random point is valid by comparing the radii and verifying $r<R$ (angle theta is just a random number taken from an uniform distribution over the [0, $2\\pi$] interval). The likelihood of this is then obtained like usual probability calculation:\n",
    "$$P(r<R) = \\iint\\frac{1}{{2 \\pi}}e^{-\\frac{x^2+y^2}{2}}dxdy=\\frac{1}{{2 \\pi}}\\int_0^{2\\pi}\\int_0^r e^{-r^2/2} rdrd\\theta = \\int_0^r e^{-r^2/2} rdr$$\n",
    "where the integral wrt $\\theta$ cancels out with the $1/2\\pi$. Substituting $r^2/2 = s$ yields $ds = rdr$, so\n",
    "\n",
    "$$\\int_0^r e^{-r^2/2} rdr = \\int_0^s e^{-s}ds = 1-e^{-s} = 1-e^{-r^2/2} = e^{-r^2/2}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is the probability we were looking for.\n",
    "\n",
    "To avoid confusion, the random number in the uniform distribution (0,1] will now be called $u_i$. So,\n",
    "\n",
    "$$u_i = e^{-r^2/2} \\implies r = \\sqrt{-2\\ln {u_i}}$$\n",
    "\n",
    "and going back to cartesian coordinates we're finally obtaining the Box-Mueller method.\n",
    "\n",
    "$$x_i = \\sqrt{-2\\ln {u_i}} \\cos(2\\pi u_{i+1})\\\\ y_i=\\sqrt{-2\\ln {u_i}} \\sin(2\\pi u_{i+1})$$\n",
    "\n",
    "So the process is:\n",
    "- We generate a pair of random numbers $u_{1,2} \\in (0,1]$ in the uniform distribution\n",
    "- Plug those into the formulas and obtain the pair $g_1(= x), g_2(= y)$: what these values do is basically take a point that follows the exact specified law and just move it up or down to simulate it having \"real error\"/being gaussian-distributed around the exact function\n",
    "- Move forward one sigma and reapply"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical example\n",
    "\n",
    "We have a 10cm long rod (hehe), one end of it is at 0°K (physically impossible but it's just an example), other end is 100°K. We're assuming the temperature along the rod is linearly growing as $T(x) = a+bx$, with $T(0) = 0, T(10) = 100$, ergo $a=0, b=10$. There's an uncertainty $\\sigma_T$ of 1K, which is the error we associate to the simulated temperatures.\n",
    "\n",
    "We \"took\" (or pretend we're taking) 10 measurements, taking $x_{T0} = 0.5 \\text {cm}$ as the first point, meaning we'll use a 1cm step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\t T\n",
      "0.5\t3.954578965470284 \n",
      "1.5\t15.65221247934697\n",
      "2.5\t23.954578965470283 \n",
      "3.5\t35.65221247934697\n",
      "4.5\t43.95457896547028 \n",
      "5.5\t55.65221247934697\n",
      "6.5\t63.95457896547028 \n",
      "7.5\t75.65221247934697\n",
      "8.5\t83.95457896547029 \n",
      "9.5\t95.65221247934697\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import random, numpy as np\n",
    "\n",
    "x = 0.5 #placeholder to say x0 is given by the starting x value we took, in this case 0.5\n",
    "step = 1 #step size (after-edit note: THEY'RE NOT THE SAME THING, UNCERTAINTY IS NOT TO BE TAKEN AS THE STEP SIZE, THIS IS A SPECIFIC EXAMPLE)\n",
    "u1 = random.random()\n",
    "u2 = random.random() #both of these should fall within (0,1] although the random() function per se includes 0 and excludes 1\n",
    "a = 0 #lower bound\n",
    "b = 10 #upper bound\n",
    "\n",
    "T = lambda x, a, b: a+(b*x) #generic law of temperature distribution: we chose to simulate a rod where the temperature from one end to the other end grows linearly\n",
    "T_delta = lambda x, a, b: a+(b*(x+step)) #same formula plus the increment we called sigma\n",
    "\n",
    "BM_x = lambda u1, u2: np.real(sqrt((-2) * (np.log(u1))) * (np.cos((2 * np.pi * u2)))) #remember we have two formulas because we're making a graph of (x, y) points\n",
    "BM_y = lambda u1, u2: np.real(sqrt((-2) * (np.log(u1))) * (np.sin((2 * np.pi * u2)))) #I should stop using lambdas like this, also BM means Box Mueller\n",
    "\n",
    "#! Python misunderstands the argument sign within the square root because of the -2 and wrongly returns a complex typed value, which of course has null imaginary part \n",
    "#! as the whole calculation actually returns a positive argument. A \"dirty fix\" is, as shown above, forcing a type conversion to np.real().\n",
    "#? In theory the above formula should be looped to generate different random values each time?\n",
    "\n",
    "print(\"x\\t T\")\n",
    "while x <= 10: #10 is the centimeters, length of the bar\n",
    "    T1 = T(x, a, b)\n",
    "    T2 = T_delta(x, a, b)\n",
    "\n",
    "    T_random1 = step * BM_x(u1, u2) + T1 \n",
    "    T_random2 = step * BM_y(u1, u2) + T2 #each cycle spits out 2 random temperature values, neat!\n",
    "    print(f\"{x}\\t{T_random1} \\n{x+step}\\t{T_random2}\")\n",
    "    x += 2*step #each cycle we move 2 steps ahead to generate the next pair"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson distributed values\n",
    "\n",
    "$$P(x) = \\frac{\\mu^x}{x!}e^{-\\mu}, x \\in \\Z$$\n",
    "Usual business:\n",
    "$$r = \\sum_{x=0}^n P(x)dx = \\sum_{x=0}^n \\frac{\\mu^x}{x!}e^{-\\mu}$$\n",
    "\n",
    "which, for $n$ to infinity, this converges to 1.\n",
    "\n",
    "And we just opt for the look-up table for simplicity.\n",
    "\n",
    "For $\\mu = 8.4$ (arbitrarily chosen, could be anything else):\n",
    "\n",
    "- $n$ is our \"index\" as well as the value of $n$ events we're measuring the probability of\n",
    "- $p_n$ is the obtained value, or the poisson probability of obtaining the number $n$ (so basically $p_n = P(n)$)\n",
    "- $s_n$ is the partial sum up to term $n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n   p       s\n",
    "\n",
    "0   0.0002  0.0002\n",
    "\n",
    "1   0.0019  0.0021 \n",
    "\n",
    "2   0.0079  0.0100\n",
    "\n",
    "3   0.022   0.032\n",
    "\n",
    "4   0.0..(?)\n",
    "\n",
    "5   0.078   0.157\n",
    "\n",
    "6   0.11    0.267    \n",
    "\n",
    "7\n",
    "...\n",
    "\n",
    "after entry 9, p will decrease (because $9 > \\mu$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbff6b447f4414ef932823147e4ed195d87834149e57d3c5b9d311f86c61fe5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
